
<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>NLP Text Classifier</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/style.css" rel="stylesheet">

</head>
<nav class="nav-bar fixed-top ">
        <div><h4 class="heading-1">Applied Machine Learning and Life Cycle</h4></div>
        <hr>
      
        <div><h4 class="heading-2">Natural Language Processing</h4></div>
        <div class="shadow">
                <ul class="list-inline">
                <li class="list-inline-item"><a href="problem.html"><h6 >Problem Framing</h6></a></li>
                <li class="list-inline-item"><a href="solution.html"><h6>Solution</h6></a></li>
                <li class="list-inline-item"><a href="classification1.html"><h6>Text Classification</h6></a></li>
                <li class="list-inline-item"><a href="results.html"><h6>Results</h6></a></li>
                <li class="list-inline-item"><a href="tune.html"><h6>Tune Hyperparameter</h6></a></li>
                <li class="list-inline-item"><a href="conclusion.html"><h6>Conclusion</h6></a></li>
              </ul>
        </div>
    </nav>
<body>
     <div class="container">
        <div class="row content-row">
            <div class="col-4 menu-col">
                <div class="list-group " id="list-tab" role="tablist">
                    <a class="list-group-item list-group-item-action" id="list-introduction-list" data-toggle="list" href="#list-introduction" role="tab" aria-controls="introduction">Introduction</a>
                    <a class="list-group-item list-group-item-action" id="list-gather-data-list" data-toggle="list" href="#list-gather-data" role="tab" aria-controls="gather-data">Step 1: Gather Data</a>
                    <a class="list-group-item list-group-item-action" id="list-explore-data-list" data-toggle="list" href="#list-explore-data" role="tab" aria-controls="explore-data">Step 2: Explore Data</a>
                    <a class="list-group-item list-group-item-action" id="list-model-selection-list" data-toggle="list" href="#list-model-selection" role="tab" aria-controls="model-selection">Step 3: Model Selection</a>
                    <a class="list-group-item list-group-item-action" id="list-data-processing-list" data-toggle="list" href="#list-data-processing" role="tab" aria-controls="data-processing">Step 4: Data-Processing</a>
                    <a class="list-group-item list-group-item-action" id="list-b-t-e-model-list" data-toggle="list" href="#list-b-t-e-model" role="tab" aria-controls="b-t-e-model"> Step 5: Build,Train and Evaluate Model</a>                        
               </div>
            </div>
            <div class="col-8 content-col">
                <div class="tab-content" id="nav-tabContent">
                    <div class="tab-pane fade show active" id="list-introduction" role="tabpanel" aria-labelledby="list-intoduction-list">
                        <h3>Introduction</h3>
                            <p class="main-content">Text classification algorithms have gained high importance among variety of software systems that process text data at scale. Text classification can be categorized as:</P>
                            <h4>Topic Classification </h4>
                            <p class="main-content">
                            Topic classification is categorizing a text document into one of a predefined set of topics. In many topic classification problems, this categorization is based primarily on keywords in the text.  SPAM filter, Inappropriate comment detection in discussion forums are two examples of topic classification.
                            </p>
                            <h4>Sentiment Analysis</h4>		
                            <p class="main-content">Sentiment analysis (SA) has become a very active research area in natural language processing (NLP) and has attracted increasing interest in data mining, Web mining, and text mining.The goal  is to identify the polarity of text content: the type of opinion it expresses. This can take the form of a binary like/dislike rating, or a more granular set of options, such as a star rating from 1 to 5. One example of sentiment analysis include analyzing Twitter posts to analyze hate speech/offensive language in tweets.
                            Sentiment analysis includes several tasks such as opinion extraction,polarity determination, affect analysis, review mining, etc.
                            </p>      
                            <p class="main-content">Here is the worlflow to solve machine learning problem </p> 
                                <ul class="list-2">
                                    <li>Step 1: Gather Data</li>
                                    <li>Step 2: Explore Data</li>
                                    <li>Step 3: Choose a Model</li>
                                    <li>Step 4: Prepare Data</li>
                                    <li>Step 5: Build, Train and Evaluate Model</li>
                                    <li>Step 6: Tune Hyperparameter</li>
                                </ul>   
                            <img class="work-flow" src="images/ml-lifecycle.png" alt="life-cycle">
                    </div>
                    <div class="tab-pane fade" id="list-gather-data" role="tabpanel" aria-labelledby="list-gather-data-list">
                            <h3>Step 1: Gather Data</h3>
                            <p class="main-content">Gathering data is the most important step in solving any supervised machine learning problem. Our text classifier can only be as good as the dataset it is built from.</p>
                            <p class="main-content">We are tackling a specific problem, we used the positive/negative(Neutral/Hate or offensive language) polarity of the Twitter Tweets dataset. The dataset contains tweets posted by people on Twitter, it is labeled as  0-Hate Speech, 1-Offensive language and 2-Neither.</p>
                    </div>
                    <div class="tab-pane fade" id="list-explore-data" role="tabpanel" aria-labelledby="list-explore-data-list">
                            <h3>Step 2: Explore Data</h3>
                            <p class="main-content">Understanding the characteristics of our data beforehand enables us:</p>
                                <ul class="list-1"> 
                                    <li> to bring important aspects of the data into focus for further analysis.</li>
                                    <li> to build a better model</li> 
                                    <li> to obtain a higher accuracy. </li>
                                    <li> to understand how much data we should use for training less data for training, or fewer computational resources.</li>
                                </ul>
                            <p>The key to managing such an exploration is to be organized. Keeping records about the exploration, recording thoughts and ideas along the way, and organizing findings are all important. This is a complex undertaking, though possibly very rewarding.</p>
                            <h4>Load the Dataset</h4>
                            <p>First up, let’s load the dataset into Python.</p>
                            <h4>Check the Dataset</h4>
                            <p>After loading the data, it’s good practice to run <strong> some checks</strong> on it: so pick a few samples and manually check if they are consistent with our expectations. For example, print a few random samples to see if the tweet label corresponds to the tweet. </p>
                            <h4>Collect Key Metrics</h4>
                        
                            <p>Once we have verified the data,  we collected the following important metrics that can help characterize our text classification problem:</p>
                            <ol class="list-1">
                                <li><strong>Number of samples:</strong> Total number of examples we have in the data.</li>
                                <li><strong>Number of classes:</strong> Total number of topics or categories in the data.</li>
                                <li><strong>Number of samples per class:</strong> Number of samples per class (topic/category). In a balanced dataset, all classes will have a similar number of samples; in an imbalanced dataset, the number of samples in each class will vary widely.</li>
                                <li><strong>Number of words:</strong>Total number of words in dataset</li>
                                <li><strong>Distribution of samples among classes:</strong></li>
                            </ol>
                            <p>The following table shows the summary of metrics.</p>
                            <div >
                                <table class="table table-bordered metrics-table">
                                    <thead>
                                        <tr>
                                            <th style="text-align: left"> Metric Name </th>
                                            <th style="text-align: center">Metric Value</th>
                                        </tr>
                                    </thead>
                                        <tbody>
                                            <tr>
                                                <td style="text-align: left">Number of samples</td>
                                                <td style="text-align: center">23780</td>
                                            </tr>
                                            <tr>
                                                <td style="text-align: left">Number of classes</td>
                                                <td style="text-align: center">3</td>
                                                </tr>
                                            <tr>
                                                <td>Number of samples per class</td>
                                                <td style="text-align: center">     1 - 19190     |      2 - 4163     |     0 - 1430</td>
                                             </tr>
                                             <tr>
                                                <td>Number of words</td>
                                                <td style="text-align: center"> 348721</td>
                                            </tr>
                                        </tbody>
                                </table>
                            </div>
                            <h6>Table 1. Twitter dataset metrics  </h6>
                            <div class="dist">
                            
                            <img class="class-dist" src="images/class-dist1.png" alt="class-dist">
                            <h6><strong>Fig.1 Tweets distribution per class</strong></h6>
                            </div>
                    </div>
                    <div class="tab-pane fade" id="list-model-selection" role="tabpanel" aria-labelledby="list-model-selection-list">
                            <h3>Step 3: Choose a Model</h3>
                            <p>At this point, we have assembled our dataset and gained insights into the key characteristics of our data. Next, based on the metrics we gathered in Step 2, we should think about which classification model we should use. This means/ asking questions such as, “How do we present the text data to an algorithm that expects numeric input?” (this is called data preprocessing and vectorization), “What type of model should we use?”, “What configuration parameters should we use for our model?”, etc.</p>
                            <p>Given that the best options might not be obvious, a naive solution would be to try every possible option exhaustively, pruning some choices through intuition. However, that would be tremendously expensive.</p>
                            <p>Our goal is to find the algorithm that achieves close to maximum accuracy while minimizing computation time required for training. We will try to implement diefferent data processing techniques alternating and different model architectures. This will help us identify dataset parameters that influence optimal choices.</p>
                            <p>Below is the summary of our model selection algorithm</p>
                            <h4>Data preparation and Model Building Algorithm</h4>
                            <div class="algorithm-1">
                                <ol>
                                    <li>Calculate the samples</li>
                                    <li>Transform the classes into Binary classes</li>
                                    <li>Clean the text
                                        <ol>
                                            <li>Remove puncuation</li>
                                            <li>Convert words into lower case and split them</li>
                                            <li>Removing special characters</li>
                                            <li>Stemming</li>
                                        </ol>
                                    </li>
                                    <li>Split the dataset into training and testing dataset</li>
                                    <li>Apply Feature Engineering techniques. We will apply two traditional models and one advance model for text feature extraction
                                        <ol>
                                            <li>Bag of Words Model</li>
                                            <li>TF-IDF Model</li>
                                            <li>Word2Vec</li>
                                        </ol>
                                    </li>
                                    <li>Score the importance of vectors</li>
                                    <li>Build different models before and after balancing the data
                                        <ol>
                                            <li>Single classifiers</li>
                                            <li>Deep learning and sequential models</li>
                                            <li>Ensemble models</li>
                                        </ol>
                                    </li>
                                    <li>Measure the Model performance with different hyperparameters to find the best model configuration of the dataset</li> 
                                </ol>
                            </div>
                            <div></div>
                        </div>
                        <div class="tab-pane fade" id="list-data-processing" role="tabpanel" aria-labelledby="list-data-processing-list">
                                <h3>Step 4: Prepare the Data</h3>
                                <h4>Text Preprocessing</h4>
                                    <p>For this particular data set, our text cleaning step includes :
                                       HTML decoding, remove stop words, change text to lower case, remove punctuation, remove bad characters, and so on.
                                    </p>
                                <p>
                                        During the data exploration we found two major issues:</p>
                                        <ol class="list-1">
                                            <li>Multiple-Classes</li>
                                            <li>Imbalanced dataset</li>
                                        </ol>
                                 <p>To overcome multiple class issue we transformed the classes to <strong>Binary classes</strong>.Combining Hate Speech and Offensive language as 0 and Neither as 1 . 
                                    Below table shows the binary classification data distribution.
                                </p>
                                <table class="table table-bordered metrics-table">
                                    <thead>
                                        <tr>
                                            <td>Class </td>
                                            <td>Tweets</td> 
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>0- Hate Speech</td>
                                            <td>1430</td>
                                        </tr>
                                        <tr>
                                            <td>1- Offensive Language</td>
                                            <td>19190</td>
                                        </tr>
                                        <tr>
                                             <td>2-Offensive Language</td>
                                             <td> 4163</td>
                                        </tr>       
                                    </tbody>
                                </table>
                                <p>We transformed the classes into binary classes and recorded the results as follows:</p>
                                <table class="table table-bordered metrics-table">
                                        <thead>
                                            <tr>
                                                <td>Class </td>
                                                <td>Tweets</td>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td>0 - (Hate Speech + Offensive language)</td>
                                                <td>20620</td>  
                                            </tr> 
                                            <tr>
                                                <td>1- Neither</td>
                                                <td> 4163</td> 
                                            </tr>    
                                        </tbody>
                                    </table>
                                <h4>Split the dataset</h4>
                                <p>Before our data can be fed to a model, it needs to be transformed to a format the model can understand.
                                   First, the data samples that we have gathered may be in a specific order. We do not want any information associated with the ordering of samples to influence the relationship between texts and labels. 
                                   For example, if a dataset is sorted by class and is then split into training/validation sets, these sets will not be representative of the overall distribution of data.
                                   A simple best practice to ensure the model is not affected by data order is to always shuffle the data before doing anything else.</p>
                                <p>Before training, and even vectorizing, let's split our data into training and testing sets. It's important to do this before doing anything with the data so we have a fresh test set.</p>
                                <h4>Feature Extraction</h4>
                                <p>Second, machine learning algorithms take numbers as inputs. This means that we will need to convert the texts into numerical vectors. There are three steps to this process:</p>
                                <h5>Bag of Words representation</h5>
                                        <ol class="list-1">
                                            <li>tokenizing strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators.</li>
                                            <li>counting the occurrences of tokens in each document.</li>
                                            <li>normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents.</li>
                                        </ol>
                                        <p>We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. 
                                           Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</p>
                                        <div class="bow-matrix">
                                                     
                                                        array([[0, 0, 0, ..., 0, 0, 0],
                                                               [0, 0, 0, ..., 0, 0, 0],
                                                               [0, 0, 0, ..., 0, 0, 0],
                                                               ...,
                                                               [0, 0, 0, ..., 0, 0, 0],
                                                               [0, 0, 0, ..., 0, 0, 0],
                                                               [0, 0, 0, ..., 0, 0, 0]], dtype=int64)
                                                               class scipy.sparse.csr.csr_matrix
                                        </div>
                                        <p>This representation is used in conjunction with models that don’t take ordering into account, such as logistic regression, multi-layer perceptrons, gradient boosting machines, support vector machines.</p>
                                        <h5>Tf–idf term weighting</h5>
                                        <p>Word counts are a good starting point, but are very basic.
                                        One issue with simple counts is that some words like “the” will appear many times and their large counts will not be very meaningful in the encoded vectors.
                                        An alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF. This is an acronym than stands for “Term Frequency – Inverse Document” Frequency which are the components of the resulting scores assigned to each word.</p>
                                        <p>
                                        Term Frequency: This summarizes how often a given word appears within a document.
                                        Inverse Document Frequency: This downscales words that appear a lot across documents.
                                        Without going into the math, TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.</p>
                                        <p>The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents. Alternately, if you already have a learned CountVectorizer, you can use it with a TfidfTransformer to just calculate the inverse document frequencies and start encoding documents.The same create, fit, and transform process is used as with the CountVectorize</p>
                                        <div class="tf-matrix" >
                                                [ 8.81535838  8.1222112  10.20165274 ... 10.20165274 10.20165274
                                                10.20165274]
                                               (1, 26961)
                                               [[0. 0. 0. ... 0. 0. 0.]]
                                        </div>
                                        <h5>Word2Vec Representation </h5>
                                       <p>Word2vec is a two-layer neural net that processes text. Its input is a text corpus and its output is a set of vectors: feature vectors for words in that corpus. While Word2vec is not a deep neural network, it turns text into a numerical form that deep nets can understand.</p>
                                        <table class="table table-bordered metrics-table">
                                            <thead style="margin-top:2px; text-align: center">
                                                <tr>
                                                    <td>Representation</td>
                                                    <td>Results</td>     
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td>BOW</td>
                                                    <td>
                                                            array([[0, 0, 0, ..., 0, 0, 0],
                                                            [0, 0, 0, ..., 0, 0, 0],
                                                            [0, 0, 0, ..., 0, 0, 0],
                                                            ...,
                                                            [0, 0, 0, ..., 0, 0, 0],
                                                            [0, 0, 0, ..., 0, 0, 0],
                                                            [0, 0, 0, ..., 0, 0, 0]], dtype=int64)
                                                            class scipy.sparse.csr.csr_matrix
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>Tf–idf term weighting</td>
                                                    <td>
                                                        [ 8.81535838  8.1222112  10.20165274 ... 10.20165274 10.20165274
                                                        10.20165274]
                                                        (1, 26961)
                                                        [[0. 0. 0. ... 0. 0. 0.]]
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>Word2Vec</td>
                                                   <td>.....</td> 
                                                </tr>
                                            </tbody>
                                        </table>
                                     <h4>Balance the data</h4> 
                                     <p>
                                     By calculating if our model only chose to predict 0(hate and offensive language), the larger class, we would get a ~60% accuracy. This means that in our binary classification model, where random chance is 50%, a 60% accuracy wouldn't tell us much. We would definitely want to look at precision and recall more than accuracy.
                                     We can balance our data by using a form of oversampling called SMOTE. SMOTE looks at the minor class, neutrals in our case, and creates new, synthetic training examples. 
                                    </p>
                                    <p>After balancing the data our records: <strong> [(0,16516), (1,16516)]</strong></p>
                                    <p> Now our data is cleaned and processed for model input.</p>
                        </div>
                        <div class="tab-pane fade" id="list-b-t-e-model" role="tabpanel" aria-labelledby="list-b-t-e-model-list">
                                <h3>Step 5: Build, Train, and Evaluate Model</h3>
    
                                <p>We tried different model building approaches:</p>
                                <ol class="list-1">
                                    <li>First approach:  Train different models<strong>(MultinomialNB,LSVC,LR)</strong> with BOW or tf-idf matrix on imbalanced dataset using Pipeline class in Scilkit-Learn that behaves like a compound classifier.</li>
                                    <li>Second approach: Train deep learning Models (LSTM,CNN,RNN) using <strong>word embeddings </strong></li>
                                    <li>Third approach: Train different ensemble models <strong>(NB, Knn)</strong> with BOW on balanced dataset using <strong>SMOTE()</strong></li>
                                </ol>
                                <h5>First approach: Model training with BOW and tf-idf mnatrix using Pipeline class in Scilkit-Learn</h5>
                                <img class="pipeline" src="images/pipeline.png" alt="pipeline">
                                <p><strong>Fig 1. Model training using Scilkit-Learn Pipe class</strong></p>
                                <br>
                                
                                
                                <h5>Second approach: Train deep learning Models <strong>(LSTM,CNN,RNN) </strong>using <strong>word embeddings </strong></h5>
                                
                                <p>
                                        In deep learning text classification we followed this approach :</p>
                                        <ul class="list-1">
                                        <li>Download data from balanced data</li>
                                        <li>Process the dataset</li>
                                        <li>Build neural network with LSTM Build neural network with LSTM and CNN Use pre-trained GloVe word embeddings Word Embeddings from Word2Vec.</li>
                                    </ul>
                                
                                <h5>Third approach: Train different ensemble models <strong>(Bagging,Boosting,Voting)</strong> with BOW on balanced dataset using <strong>SMOTE()</h5>
                             <p>
                                    Several ensemble learning techniques are evaluated to generate computational models including: Bagging, Boosting, Voting and Random Forests. We followed these steps for training Ensemble models:
                             </p>
                             <img class="pipeline" src="images/ensemble.png" alt="pipeline">
                             <p style="margin-left:20px;">We trained different ensemble clssifiers with these parameters</p>
                             <table class="table table-bordered results-table1">
                                 <thead style="text-align: center; margin-top:2px; line-height: 10px; vertical-align: center">
                                     <th></th>
                                    <th style="font-weight: 100;">Name</th>
                                     <th style="font-weight: 100;">Type</th>
                                     <th style="font-weight: 100;"> Parameters</th>
                                 </thead>
                                 <tbody style="text-align: center; margin-top:2px; line-height: 10px;">
                                     <tr>
                                         <td style="font-weight: 100;">clf1</td>
                                         <td style="font-weight: 100;">Gaussian NB (GNB)</td>
                                         <td style="font-weight: 100;">Single classifier</td>
                                         <td></td>
                                    </tr>
                                    <tr>
                                            <td style="font-weight: 100;">clf2</td>
                                            <td style="font-weight: 100;">k-NN</td>
                                            <td style="font-weight: 100;">Single classifier</td>
                                            <td style="font-weight: 100;">k=5</td>
                                       </tr>
                                       <tr>
                                            <td style="font-weight: 100;">clf3</td>
                                            <td style="font-weight: 100;">Decision Tree</td>
                                            <td style="font-weight: 100;">Single classifier</td>
                                            <td style="font-weight: 100;">Gini index, min_sample_split= 2</td>
                                       </tr>
                                       <tr>
                                            <td style="font-weight: 100;">eclf1</td>
                                            <td style="font-weight: 100;">Random Forest</td>
                                            <td style="font-weight: 100;">Ensemble Randomization</td>
                                            <td style="font-weight: 100;">n_estimators= 20</td>
                                       </tr>
                                       <tr>
                                            <td style="font-weight: 100;">eclf2</td>
                                            <td style="font-weight: 100;">Bagging</td>
                                            <td style="font-weight: 100;">Ensemble Bagging</td>
                                            <td style="font-weight: 100;">Estimator= Decision Tree</td>
                                       </tr>
                                       <tr>
                                            <td style="font-weight: 100;">eclf3</td>
                                            <td style="font-weight: 100;">Boosting</td>
                                            <td style="font-weight: 100;">Ensemble Boosting</td>
                                            <td style="font-weight: 100;">Estimator= Decision Tree</td>
                                       </tr>
                                       <tr>
                                            <td style="font-weight: 100;">eclf4</td>
                                            <td style="font-weight: 100;">Voting</td>
                                            <td style="font-weight: 100;">Ensemble Voting</td>
                                            <td style="font-weight: 100;">Estimators= LSVC,RF,LR,NB</td>
                                       </tr>
                                 </tbody>
                             </table>
                            </div>
                        <div class="tab-pane fade" id="list-tune" role="tabpanel" aria-labelledby="list-tune-list">
                                    <h3>Step 5: Tune Hyperparameter</h3>
                                </div>
                            


                </div>
            </div>
            
                

                       
                                                    
                                
                                           
                                

                                       
                                    
                                  
                            
                                        
            
                 
        </div>
    </div>



   <!-- /#wrapper -->

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Menu Toggle Script -->
  <script>
    $("#menu-toggle").click(function(e) {
      e.preventDefault();
      $("#wrapper").toggleClass("toggled");
    });
  </script>

</body>

</html>
