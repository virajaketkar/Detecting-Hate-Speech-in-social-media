{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Hate Speech Analysis\n",
    "When working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going tp train multiple models to compare and decide which one is the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "The data we are using from twitter.The data file contains 5 columns:\n",
    "\n",
    "count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "\n",
    "hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "import gensim\n",
    "import re\n",
    "import logging\n",
    "from numpy import random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "from gensim.models import Word2Vec  \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.options.mode.chained_assignment = None\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "5           5      3            1                   2        0      1   \n",
      "6           6      3            0                   3        0      1   \n",
      "7           7      3            0                   3        0      1   \n",
      "8           8      3            0                   3        0      1   \n",
      "9           9      3            1                   2        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
      "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
      "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
      "9  \" @rhythmixx_ :hobbies include: fighting Maria...  \n",
      "348721\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_data.csv')\n",
    "#df = df[pd.notnull(df['class'])]\n",
    "#df = df.head(5000)\n",
    "print(df.head(10))\n",
    "print(df['tweet'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 3 million words in. tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0 - hate speech 1 - offensive language 2 - neitherda\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20620\n",
       "1     4163\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class']=[1 if b == 2 else 0 for b in df['class']]\n",
    "# Transform into binary classification\n",
    "#df['class'] = [1 if b == 2 else 0 for b in df['class']]\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'count')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f284668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shape of our data\n",
    "df.columns\n",
    "df.head(10)\n",
    "plt.figure(figsize=(10,4))\n",
    "ax=df['class'].value_counts().plot(kind='bar');\n",
    "ax.set_xlabel(\"class\")\n",
    "ax.set_ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing\n",
    "The text cleaning techniques we have seen so far work very well in practice. Depending on the kind of texts you may encounter, it may be relevant to include more complex text cleaning steps. But keep in mind that the more steps we add, the longer the text cleaning will take.\n",
    "For this particular data set, our text cleaning step includes HTML decoding, remove stop words, change text to lower case, remove punctuation, remove bad characters, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>rt mayasolovely woman shouldnt complain cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt mleew17 boy dats coldtyga dwn bad cuffin da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt urkindofbrand dawg rt 80sbaby4life ever fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rt c_g_anderson viva_based look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt shenikaroberts shit hear might true might f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t_madison_x shit blows meclaim faithful somebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__brighterdays sit hate another bitch got much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selfiequeenbri cause im tired big bitches comi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>might get ya bitch back thats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rhythmixx_ hobbies include fighting mariambitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      1   \n",
       "1           1      3            0                   3        0      0   \n",
       "2           2      3            0                   3        0      0   \n",
       "3           3      3            0                   2        1      0   \n",
       "4           4      6            0                   6        0      0   \n",
       "5           5      3            1                   2        0      0   \n",
       "6           6      3            0                   3        0      0   \n",
       "7           7      3            0                   3        0      0   \n",
       "8           8      3            0                   3        0      0   \n",
       "9           9      3            1                   2        0      0   \n",
       "\n",
       "                                               tweet  \n",
       "0  rt mayasolovely woman shouldnt complain cleani...  \n",
       "1  rt mleew17 boy dats coldtyga dwn bad cuffin da...  \n",
       "2  rt urkindofbrand dawg rt 80sbaby4life ever fuc...  \n",
       "3        rt c_g_anderson viva_based look like tranny  \n",
       "4  rt shenikaroberts shit hear might true might f...  \n",
       "5  t_madison_x shit blows meclaim faithful somebo...  \n",
       "6  __brighterdays sit hate another bitch got much...  \n",
       "7  selfiequeenbri cause im tired big bitches comi...  \n",
       "8                      might get ya bitch back thats  \n",
       "9    rhythmixx_ hobbies include fighting mariambitch  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['tweet'] = df['tweet'].apply(clean_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After text cleaning and removing stop words, we have only over 2 million words to work with!\n",
    "After splitting the data set, the next steps includes feature engineering. \n",
    "We will convert our text documents to a matrix of token counts (CountVectorizer), then transform a count matrix to a normalized tf-idf representation (tf-idf transformer). After that, we train several classifiers from Scikit-Learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.tweet\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier for Multinomial Models\n",
    "After we have our features, we can train a classifier to try to predict the tag of a post. We will start with a Naive Bayes classifier, which provides a nice baseline for this task.\n",
    "\n",
    "scikit-learn includes several variants of this classifier; the one most suitable for text is the multinomial variant.\n",
    "\n",
    "To make the vectorizer => transformer => classifier easier to work with, we will use Pipeline class in Scilkit-Learn that behaves like a compound classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8432052937378954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91     10301\n",
      "           1       0.98      0.07      0.13      2091\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     12392\n",
      "   macro avg       0.91      0.54      0.52     12392\n",
      "weighted avg       0.86      0.84      0.78     12392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved 84% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machine\n",
    "Linear Support Vector Machine is widely regarded as one of the best text classification algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8487734021949644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     10301\n",
      "           1       0.91      0.12      0.21      2091\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     12392\n",
      "   macro avg       0.88      0.56      0.56     12392\n",
      "weighted avg       0.86      0.85      0.80     12392\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumairaafzal/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic regression is a simple and easy to understand classification algorithm, and Logistic regression can be easily generalized to multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310038734667527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     10301\n",
      "           1       0.83      0.75      0.79      2091\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     12392\n",
      "   macro avg       0.89      0.86      0.87     12392\n",
      "weighted avg       0.93      0.93      0.93     12392\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumairaafzal/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
